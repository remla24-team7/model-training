# from scripts.evaluate import evaluate_model


# if __name__ == "__main__":
#     model_path = 'outputs/model.h5'
#     x_test_path = 'outputs/mutated_x_train.joblib'
#     y_test_path = 'outputs/y_train.joblib'
#     report, confusion_mat, accuracy, auc = evaluate_model(model_path, x_test_path, y_test_path,test=False)
#     print('Classification Report:', report)
#     print('Confusion Matrix:', confusion_mat)
#     print('Accuracy:', accuracy)
#     print('AUC:', auc)
